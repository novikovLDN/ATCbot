# Аудит системы: краши, БД, webhook, даты, несколько экземпляров, воркеры

**Дата:** 2025-02-15  
**Цель:** Определить корневые причины крашей (БД, миграции, webhook 502, naive/aware datetime, конфликт экземпляров Telegram, зависание воркеров) и зафиксировать шаги по исправлению.

---

## 1. База данных и миграции

### 1.1 Ошибка "pool is not initialized"

**Источник:** В коде проекта **нет** строки `"pool is not initialized"`. Такое сообщение типично для **asyncpg**, когда вызывается метод у уже **закрытого** пула (`pool.close()` выполнен, но код ещё держит ссылку на старый объект).

**Где это возможно в текущей схеме:**

1. **`database.init_db()`** (database.py):
   - Создаётся пул → выполняются миграции → пул **закрывается** → создаётся **новый** пул (`_pool = await asyncpg.create_pool(...)`).
   - Глобальная переменная `_pool` перезаписывается. Любой код, который успел взять `conn` из **старого** пула (например, воркер auto_renewal), после `close()` будет обращаться к закрытому пулу → при следующем `acquire()` или запросе asyncpg может выдать ошибку вида "pool is not initialized" / "connection pool is closed".

2. **Порядок старта:**
   - Сначала вызывается `init_db()` (создаёт пул, миграции, пересоздаёт пул).
   - Только после успешного `init_db()` выставляется `DB_READY = True` и запускаются воркеры.
   - Воркеры вызывают `database.get_pool()` и получают уже **актуальный** `_pool`. Поэтому при **нормальном** старте конфликта нет.

3. **Когда возможна ошибка:**
   - Параллельный вызов `init_db()` и обращений к пулу (например, retry_db_init и healthcheck/воркер одновременно).
   - Вызов `close_pool()` при shutdown, пока воркер ещё держит соединение и потом пытается снова взять соединение из пула.

**Рекомендации:**

- Убедиться, что воркеры и healthcheck не обращаются к БД во время выполнения `init_db()` (сейчас воркеры стартуют только при `DB_READY`, это верно).
- В `close_pool()` перед `_pool.close()` не вызывать методы старого пула из других задач; при shutdown сначала останавливать воркеры, затем освобождать advisory lock и только потом `close_pool()` (текущий порядок в main.py корректен).
- Если в логах видно "pool is not initialized" **во время миграций** — проверить, что никакой другой код не вызывает `get_pool()` или `pool.acquire()` в момент выполнения `run_migrations_safe(_pool)` и пересоздания пула. При необходимости ввести блокировку "инициализация БД идёт" и в `get_pool()` при этой блокировке ждать или возвращать ошибку.

### 1.2 Успешность миграций и готовность БД

- **Миграции** выполняются внутри `init_db()`: после создания первого пула вызывается `migrations.run_migrations_safe(_pool)`. При успехе миграций пул пересоздаётся, затем создаются таблицы по умолчанию и выставляется `DB_READY = True`.
- Если миграция падает, `init_db()` возвращает `False`, пул остаётся в состоянии "после первого create_pool" (до пересоздания). При этом `get_pool()` в других модулях вызывается только после успешного `init_db()` (при `DB_READY`), иначе воркеры не стартуют.
- **Проверка в логах:** искать строки `"Migration N applied successfully"` и `"DB_POOL_RECREATED_AFTER_MIGRATIONS"`. Отсутствие `"Database migrations applied successfully"` при наличии ошибок миграций объясняет, почему БД "не готова".

**Шаги для диагностики:**

1. Включить логирование перед/после `run_migrations_safe` и после пересоздания пула (уже есть частично).
2. При ошибке миграции логировать полный текст исключения и номер миграции (уже есть в migrations.py).
3. Убедиться, что после любой ошибки в `init_db()` глобальный `_pool` не остаётся в "полузакрытом" состоянии: при падении до пересоздания пула явно закрыть и выставить `_pool = None`.

---

## 2. Webhook и 502 Bad Gateway

### 2.1 Причина 502

502 обычно возвращает **прокси** (Nginx, Cloudflare, Railway и т.д.), когда upstream (приложение бота) не ответил вовремя, недоступен или вернул невалидный ответ.

**Типичные причины:**

- Приложение не слушает на ожидаемом хосте/порте (например, `WEBHOOK_PORT`/`PORT`).
- Таймаут прокси меньше времени обработки запроса (долгий ответ Telegram webhook).
- SSL: запрос идёт на HTTPS, а прокси не может установить соединение с бэкендом (неверный сертификат или не тот порт).
- Несколько инстансов за одним адресом, один из них падает или рестартует.

### 2.2 Что проверить в коде и конфигурации

- **Регистрация webhook** (main.py): при `config.WEBHOOK_URL` вызывается `bot.set_webhook(url=config.WEBHOOK_URL, ...)` и проверка `get_webhook_info().url`.
- **Сервер:** поднимается uvicorn на `0.0.0.0:config.WEBHOOK_PORT` (или `PORT`), маршрут POST `/telegram/webhook` в `app.api.telegram_webhook`.
- **Секрет:** в запросах должен передаваться `X-Telegram-Bot-Api-Secret-Token`; в коде проверяется `config.WEBHOOK_SECRET`.

**Рекомендуемые шаги:**

1. **Прокси (Nginx/другое):**  
   - Убедиться, что `proxy_pass` указывает на контейнер/процесс, слушающий `WEBHOOK_PORT`.  
   - Увеличить таймауты (например, `proxy_read_timeout 60s; proxy_connect_timeout 10s; proxy_send_timeout 60s;`).  
   - Проверить, что запросы к пути вида `https://your-domain/telegram/webhook` доходят до приложения (логирование входа в `telegram_webhook` handler).

2. **SSL:**  
   - Если используется HTTPS до прокси — сертификаты проверять на стороне прокси.  
   - Бэкенд может слушать HTTP (localhost), тогда прокси терминирует SSL.

3. **Логи приложения:**  
   - При каждом входящем webhook обновляется `last_webhook_update_at`.  
   - Логировать ошибки внутри `telegram_webhook` (уже есть `WEBHOOK_PROCESSING_ERROR`).  
   - Убедиться, что handler всегда возвращает 200 при успешной обработке и не падает с необработанным исключением (иначе uvicorn вернёт 5xx и прокси может отдать 502).

4. **Health endpoint:**  
   - В webhook-режиме health отдаётся через FastAPI (`app.api`). Проверить, что GET `/health` доступен и возвращает 200; если 502 даже на `/health`, проблема в доступности процесса или прокси.

---

## 3. TypeError: can't compare offset-naive and offset-aware datetimes

### 3.1 Правило в проекте

В `database.py` задано:

- В БД хранятся **naive** даты (UTC).
- При **записи** используется `_to_db_utc(dt)` (aware UTC → naive).
- При **чтении** для сравнений и возврата наружу — `_from_db_utc(dt)` или `_ensure_utc(dt)` (naive → aware UTC).
- `_normalize_subscription_row` приводит к aware UTC поля вроде `expires_at`, `created_at` и т.д.

### 3.2 Где может возникнуть ошибка

Ошибка возможна, если:

- Сравнивают значение **напрямую из БД** (naive) с `datetime.now(timezone.utc)` (aware) без приведения.
- Используют `row["expires_at"]` в сравнении с `now`, не прогоняя через `_from_db_utc` / `_ensure_utc`.

В текущем коде в критичных местах (например, `grant_access`) уже используется:

- `now = datetime.now(timezone.utc)`
- `expires_at = _ensure_utc(expires_at_raw)`
- сравнение `expires_at > now`

То есть в database.py при аккуратном использовании хелперов сравнения должны быть безопасны.

### 3.3 Рекомендации

1. **Единое правило:** любое значение `datetime` из БД перед сравнением с `now` или другими aware-датами приводить через `_from_db_utc()` или `_ensure_utc()`.
2. **Поиск по коду:** найти все места, где используется `expires_at`, `created_at`, `trial_expires_at` и т.п. из строки БД, и убедиться, что перед сравнением вызывается один из этих хелперов (в database.py уже много таких мест; проверить воркеры, handlers, app/services).
3. **В новых участках кода:** не сравнивать сырые `row["..."]` с `datetime.now(timezone.utc)`; всегда нормализовать через `_ensure_utc` или `_from_db_utc`.

---

## 4. Несколько экземпляров бота и TelegramConflictError (getUpdates)

### 4.1 Ошибка

`TelegramConflictError: terminated by other getUpdates request` означает, что с одним и тем же токеном одновременно используется **два способа получения обновлений**: например, polling (getUpdates) в одном процессе и webhook или второй процесс с polling.

### 4.2 Что уже сделано в проекте

В **main.py** реализована защита от нескольких экземпляров одного и того же приложения (один токен):

- Используется **PostgreSQL advisory lock** (`pg_advisory_lock(ADVISORY_LOCK_KEY)`).
- Ключ один на всё приложение: `ADVISORY_LOCK_KEY = 987654321`.
- Блокировка берётся после успешной инициализации БД; соединение под блокировкой держится до конца работы процесса.
- При shutdown вызывается `pg_advisory_unlock` и `pool.release(instance_lock_conn)`.

Таким образом, второй процесс того же приложения не сможет взять ту же блокировку и должен завершиться (если при неудаче `pg_advisory_lock` код делает exit). Сейчас при неудаче приобретения lock в коде выполняется `raise` после `release`, то есть процесс упадёт — этого достаточно, чтобы не было двух процессов с одним токеном, использующих один и тот же пул и один и тот же токен для polling.

Важно: advisory lock защищает от двух **экземпляров этого приложения** на одной БД. Он **не** защищает от ситуации "в одном месте webhook, в другом polling с тем же токеном" — это нужно исключать конфигурацией (либо только WEBHOOK_URL, либо только polling, без второго процесса).

### 4.3 Рекомендации

1. **Конфигурация:**  
   - В production не запускать второй процесс с тем же `BOT_TOKEN`.  
   - Если используется webhook — не запускать процесс с polling на том же токене (в коде при WEBHOOK_URL polling не стартует — корректно).

2. **Явный выход при неудаче lock:**  
   - После `raise` в блоке приобретения advisory lock процесс завершится; убедиться, что при этом не остаётся "висящих" дочерних процессов.  
   - При желании можно после неудачного lock вызывать `sys.exit(1)` с логом "another instance is running", чтобы явно обозначить причину выхода.

3. **Логи:**  
   - При старте логировать "Advisory lock acquired"; при ошибке — "Advisory lock failed, another instance may be running".  
   - При `TelegramConflictError` в логах проверять, не было ли параллельного запуска второго процесса или повторного включения getUpdates при активном webhook.

---

## 5. Фоновые задачи (auto_renewal и зависания)

### 5.1 Симптом

Воркер auto_renewal логирует ITERATION_START, но ITERATION_END не появляется; итерация не завершается; соединение с БД занято; через ~180 с срабатывает liveness watchdog и процесс завершается (os._exit(1)), что приводит к циклу перезапусков.

### 5.2 Что уже сделано в коде (auto_renewal.py)

- **Таймаут итерации:** тело итерации (acquire lock + `process_auto_renewals(bot)`) обёрнуто в `asyncio.wait_for(..., timeout=120.0)` (`ITERATION_HARD_TIMEOUT_SECONDS`). Зависшая итерация принудительно отменяется через 2 минуты.
- **Обработка TimeoutError:** при `asyncio.TimeoutError` пишется ERROR с именем воркера и `correlation_id`, выставляется `iteration_outcome = "timeout"`, исключение не пробрасывается, цикл продолжается.
- **ITERATION_END в finally:** в блоке `finally` всегда вызывается `log_worker_iteration_end(..., outcome=iteration_outcome, duration_ms=..., error_type=...)`. Таким образом, ITERATION_END логируется в любом случае (успех, таймаут, ошибка, отмена, пропуск).
- **Пул БД:** используется `acquire_connection(pool, ...)`; пул создаётся с `timeout` (DB_POOL_ACQUIRE_TIMEOUT) в `database._get_pool_config()`. Прямых вызовов VPN API (httpx) в auto_renewal нет.

Этого достаточно, чтобы даже при зависании одной итерации через 120 с она завершилась, соединения освободились, в логах появился ITERATION_END и следующий цикл по расписанию выполнился. Liveness не должен бесконечно убивать процесс только из-за зависания auto_renewal.

### 5.3 Что проверить в логах после исправления

- Для каждой итерации auto_renewal: сначала `ITERATION_START`, затем не позднее чем через ~120 с — `ITERATION_END` с полем `outcome` (success / timeout / failed / degraded / skipped).
- При зависании: через 120 с — сообщение об ошибке таймаута и ITERATION_END с `outcome=timeout`, `error_type=timeout`.
- При нормальной работе: ITERATION_END с `outcome=success` и разумным `duration_ms`.

### 5.4 Рекомендации по другим воркерам

- Для всех фоновых задач с длительной работой (reminders, trial_notifications, activation_worker, fast_expiry_cleanup и т.д.):
  - оборачивать тело итерации в `asyncio.wait_for(..., timeout=...)` с разумным лимитом (например, 120 с);
  - в `finally` всегда вызывать аналог `log_worker_iteration_end`, чтобы в логах было однозначное завершение итерации;
  - при таймауте логировать ERROR и не пробрасывать исключение, переходить к следующей итерации.
- Все вызовы `pool.acquire()` или `acquire_connection()` полагаются на общий `timeout` пула; при необходимости для отдельных долгих операций можно дополнительно ограничивать их по времени.

---

## 6. Сводка решений

| Проблема | Решение / статус |
|--------|-------------------|
| **Pool is not initialized** | Связано с использованием закрытого пула. Не держать ссылки на старый пул во время init_db; при shutdown сначала остановить воркеры, потом close_pool. При появлении в логах — проверить порядок вызовов и параллельный доступ к пулу. |
| **Миграции не выполняются / БД не готова** | Смотреть логи: "Migration N applied successfully", "DB_POOL_RECREATED_AFTER_MIGRATIONS", "Database migrations applied successfully". При ошибке миграции — исправить SQL или порядок миграций; при падении init_db — явно закрывать и обнулять _pool. |
| **502 Bad Gateway (webhook)** | Проверить прокси (адрес, порт, таймауты), SSL, что приложение слушает нужный порт и что handler webhook не падает с необработанным исключением. Логировать вход в webhook и ошибки. |
| **Naive vs aware datetime** | Везде использовать _from_db_utc / _ensure_utc для дат из БД перед сравнением с now. Провести поиск по коду по expires_at, created_at и т.д. |
| **Несколько экземпляров / TelegramConflictError** | Advisory lock в main.py уже мешает второму экземпляру приложения. Убедиться, что не запускается второй процесс с тем же токеном и что не совмещаются webhook и polling на одном токене. |
| **Зависание auto_renewal, нет ITERATION_END** | Реализовано: wait_for(120s), обработка TimeoutError, ITERATION_END в finally. В логах проверять пару ITERATION_START / ITERATION_END и при таймауте — outcome=timeout. |

---

## 7. Рекомендуемые логи для подтверждения

После внедрения исправлений в production полезно убедиться по логам:

1. **БД и миграции:**  
   - `"DB connectivity probe successful"`  
   - `"Applying migration N: ..."` и `"Migration N applied successfully"`  
   - `"DB_POOL_RECREATED_AFTER_MIGRATIONS"`  
   - `"Database migrations applied successfully"`  
   - Отсутствие ошибок вида "pool is not initialized" во время старта и миграций.

2. **Webhook:**  
   - При запросе к webhook — запись в лог о приёме (например, update_id); при ошибке — WEBHOOK_PROCESSING_ERROR.  
   - Со стороны прокси — 200 на запросы к `/telegram/webhook`, отсутствие 502 при штатной нагрузке.

3. **Один экземпляр:**  
   - Один раз при старте: `"Advisory lock acquired"`.  
   - Отсутствие TelegramConflictError в логах при одном процессе.

4. **Воркер auto_renewal:**  
   - Каждая итерация: лог с `"event": "ITERATION_START"` и затем лог с `"event": "ITERATION_END"` с полями `outcome`, `duration_ms`, при таймауте — `error_type=timeout`.  
   - При таймауте: ERROR с текстом вида "auto_renewal: iteration timed out after 120s (worker=auto_renewal correlation_id=...)".

Этого достаточно, чтобы подтвердить работоспособность исправлений по описанным пунктам.
